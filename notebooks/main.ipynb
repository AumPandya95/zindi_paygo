{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "mod_path = os.path.join(Path.cwd().parent)\n",
    "if mod_path not in sys.path:\n",
    "    sys.path.append(mod_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from src.data.ingestion import DataIngestion\n",
    "from src.features.engineering import FeatureEngineering\n",
    "from src.features.encoding import FeatureEncoding\n",
    "from src.model.tree_based import ModelXgBoost\n",
    "from src.data.validation_file import SubmissionFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aumaron/.local/share/virtualenvs/zindi_payg-FXkRANRI/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Should be run always [train and test]\n",
    "train, test = DataIngestion(mode=\"dev\").execute()\n",
    "train.dropna(subset=['Region'], how='all', inplace=True)\n",
    "test.dropna(subset=['Region'], how='all', inplace=True)\n",
    "train.drop(columns=['Town'], inplace=True)\n",
    "test.drop(columns=['Town'], inplace=True)\n",
    "# test = DataIngestion(mode=\"test\").execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FEATURE_ID_MAPPING = {\n",
    "#     \"Occupation\": 0,\n",
    "#     \"MainApplicantGender\": 1\n",
    "# }\n",
    "train = FeatureEngineering().execute(train)\n",
    "test = FeatureEngineering().execute(test)\n",
    "train.drop(\n",
    "    columns=[\n",
    "        'TransactionDates',\n",
    "        'PaymentsHistory',\n",
    "        'RegistrationDate',\n",
    "        'UpsellDate',\n",
    "        'SupplierName',\n",
    "        'PaymentMethod',\n",
    "        'ExpectedTermDate',\n",
    "        'FirstPaymentDate',\n",
    "        'LastPaymentDate',\n",
    "#         'SplitTransactionDates'\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "test.drop(\n",
    "    columns=[\n",
    "        'TransactionDates',\n",
    "        'PaymentsHistory',\n",
    "        'RegistrationDate',\n",
    "        'UpsellDate',\n",
    "        'SupplierName',\n",
    "        'PaymentMethod',\n",
    "        'ExpectedTermDate',\n",
    "        'FirstPaymentDate',\n",
    "        'LastPaymentDate',\n",
    "#         'SplitTransactionDates'\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_Train and Y_Train Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for Train\n",
    "import pandas as pd\n",
    "\n",
    "new_payments_df = train[[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"]]\n",
    "y_train = pd.concat([new_payments_df, new_payments_df.T.stack().reset_index(name='y')['y']], axis=1)[[\"y\"]]\n",
    "\n",
    "all_x_dfs = {\"df_0\": train.drop([\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"], axis=1)}\n",
    "for i in range(1, 6):\n",
    "    temp_df = deepcopy(all_x_dfs[f\"df_{i - 1}\"])\n",
    "    m_df = new_payments_df[[f\"m{i}\"]]\n",
    "    temp_df = pd.concat([temp_df, m_df], axis=1)\n",
    "    temp_df.rename(columns={f\"m{i}\": \"new_payment\"}, inplace=True)\n",
    "    temp_df = FeatureEngineering().get_updated_df(base_df=temp_df)\n",
    "    all_x_dfs[f\"df_{i}\"] = temp_df\n",
    "\n",
    "x_train = pd.concat([all_x_dfs[f\"df_{i}\"] for i in range(6)], ignore_index=True)\n",
    "x_train.drop(columns=['SplitPaymentsHistory'], inplace=True)\n",
    "del new_payments_df, temp_df, m_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID variable is saved separately\n",
    "# x_train_id = x_train[['ID']]\n",
    "x_train.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "test_id = test[['ID']]\n",
    "test.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87570, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_categorical_features(overall_df,\n",
    "                                encoded_frame,\n",
    "                                categorical_variable: Optional[Union[list, str]] = None,\n",
    "                                categories_to_filter: Optional[list] = None):\n",
    "    \"\"\"\n",
    "    Filter category or categories in a specifc or multiple categorical variables from the encoded frame\n",
    "\n",
    "    \"\"\"    \n",
    "    # Categories to filter\n",
    "    if categories_to_filter:\n",
    "        filtered_frame = encoded_frame[encoded_frame.columns[encoded_frame.columns.isin(categories_to_filter)]]\n",
    "    else:\n",
    "        categories = []\n",
    "        if isinstance(categorical_variable, list):\n",
    "            for _variable in categorical_variable:\n",
    "                categories.extend(overall_df[_variable].unique().tolist())\n",
    "        else:\n",
    "            categories.extend(overall_df[categorical_variable].unique().tolist())\n",
    "        filtered_frame = encoded_frame[encoded_frame.columns[encoded_frame.columns.isin(categories)]]\n",
    "    \n",
    "    return filtered_frame\n",
    "\n",
    "\n",
    "def encode_and_drop(full_array, data_type, tr_encoder=None):\n",
    "    categorical_array = full_array[full_array.select_dtypes(exclude=['number']).columns]\n",
    "    numerical_array = full_array.drop(columns=full_array.select_dtypes(exclude=['number']).columns)\n",
    "    if not tr_encoder:\n",
    "        encoder = FeatureEncoding()\n",
    "    else:\n",
    "        encoder = tr_encoder\n",
    "    encoded_array = encoder.one_hot_encoding(\n",
    "    categorical_frame=categorical_array,\n",
    "    type_of_data=data_type,\n",
    "    conv=True,\n",
    "    drop=None,\n",
    "    handle_unknown=\"ignore\"\n",
    ")\n",
    "    final_array = pd.concat([numerical_array.reset_index(drop=True),\n",
    "                             encoded_array.reset_index(drop=True)], axis=1)\n",
    "    final_array.index = numerical_array.index\n",
    "    encoded_array.index = numerical_array.index\n",
    "\n",
    "    return numerical_array, encoded_array, final_array, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For x_train\n",
    "numerical_df, encoded_categories, encoded_train, encoding_obj = encode_and_drop(x_train, \"train\", None)\n",
    "\n",
    "filtered_df = filter_categorical_features(overall_df=train, \n",
    "                                          encoded_frame=encoded_categories, \n",
    "                                          categorical_variable=['Occupation', 'Region'])\n",
    "\n",
    "# Concatenating with the Numerical frame \n",
    "numerical_frame = numerical_df[\n",
    "    [\n",
    "#         'Deposit', \n",
    "#         'AccessoryRate', \n",
    "#         'RatePerUnit', \n",
    "#         'DaysOnDeposit', \n",
    "#         'Age',\n",
    "#         'Term', \n",
    "#         'TotalContractValue', \n",
    "        'b1', \n",
    "        'b2', \n",
    "        'b3', \n",
    "        'b4', \n",
    "        'b5'\n",
    "    ]\n",
    "]  # Filtering required variables\n",
    "\n",
    "_index = numerical_frame.index\n",
    "filtered_df = pd.concat([numerical_frame.reset_index(drop=True),\n",
    "                         filtered_df.reset_index(drop=True)], axis=1)\n",
    "filtered_df.index = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>Coast Region</th>\n",
       "      <th>Mount Kenya Region</th>\n",
       "      <th>Nairobi Region</th>\n",
       "      <th>North Rift</th>\n",
       "      <th>Nyanza</th>\n",
       "      <th>South Rift</th>\n",
       "      <th>Western</th>\n",
       "      <th>Business</th>\n",
       "      <th>Driver/Motorbike Rider</th>\n",
       "      <th>Farmer</th>\n",
       "      <th>Government Employee</th>\n",
       "      <th>Labourer</th>\n",
       "      <th>Other</th>\n",
       "      <th>Teacher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>766.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110.0</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>1230.0</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87565</th>\n",
       "      <td>1540.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87566</th>\n",
       "      <td>350.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87567</th>\n",
       "      <td>2360.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87568</th>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87569</th>\n",
       "      <td>1155.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87570 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           b1      b2      b3      b4      b5  Coast Region  \\\n",
       "0       766.0  1000.0  1245.0  1195.0   840.0           0.0   \n",
       "1       200.0  2000.0  2000.0  3000.0  2500.0           1.0   \n",
       "2      1110.0  1130.0  1230.0   990.0  1250.0           0.0   \n",
       "3      1000.0  2000.0  1884.0  1500.0  3000.0           0.0   \n",
       "4      1020.0  1240.0  1080.0  1020.0   860.0           0.0   \n",
       "...       ...     ...     ...     ...     ...           ...   \n",
       "87565  1540.0  1320.0   540.0   843.0   855.0           0.0   \n",
       "87566   350.0   150.0   100.0   100.0   215.0           0.0   \n",
       "87567  2360.0  1260.0  1704.0  1435.0  1995.0           1.0   \n",
       "87568   800.0   800.0   760.0   600.0   600.0           1.0   \n",
       "87569  1155.0  1037.0  1271.0  1210.0  1364.0           0.0   \n",
       "\n",
       "       Mount Kenya Region  Nairobi Region  North Rift  Nyanza  South Rift  \\\n",
       "0                     1.0             0.0         0.0     0.0         0.0   \n",
       "1                     0.0             0.0         0.0     0.0         0.0   \n",
       "2                     0.0             0.0         0.0     1.0         0.0   \n",
       "3                     0.0             0.0         0.0     0.0         0.0   \n",
       "4                     0.0             0.0         0.0     1.0         0.0   \n",
       "...                   ...             ...         ...     ...         ...   \n",
       "87565                 0.0             0.0         1.0     0.0         0.0   \n",
       "87566                 0.0             0.0         1.0     0.0         0.0   \n",
       "87567                 0.0             0.0         0.0     0.0         0.0   \n",
       "87568                 0.0             0.0         0.0     0.0         0.0   \n",
       "87569                 1.0             0.0         0.0     0.0         0.0   \n",
       "\n",
       "       Western  Business  Driver/Motorbike Rider  Farmer  Government Employee  \\\n",
       "0          0.0       0.0                     0.0     1.0                  0.0   \n",
       "1          0.0       0.0                     0.0     0.0                  0.0   \n",
       "2          0.0       1.0                     0.0     0.0                  0.0   \n",
       "3          1.0       0.0                     0.0     0.0                  0.0   \n",
       "4          0.0       1.0                     0.0     0.0                  0.0   \n",
       "...        ...       ...                     ...     ...                  ...   \n",
       "87565      0.0       1.0                     0.0     0.0                  0.0   \n",
       "87566      0.0       0.0                     0.0     0.0                  1.0   \n",
       "87567      0.0       0.0                     0.0     1.0                  0.0   \n",
       "87568      0.0       1.0                     0.0     0.0                  0.0   \n",
       "87569      0.0       0.0                     0.0     1.0                  0.0   \n",
       "\n",
       "       Labourer  Other  Teacher  \n",
       "0           0.0    0.0      0.0  \n",
       "1           0.0    0.0      1.0  \n",
       "2           0.0    0.0      0.0  \n",
       "3           0.0    1.0      0.0  \n",
       "4           0.0    0.0      0.0  \n",
       "...         ...    ...      ...  \n",
       "87565       0.0    0.0      0.0  \n",
       "87566       0.0    0.0      0.0  \n",
       "87567       0.0    0.0      0.0  \n",
       "87568       0.0    0.0      0.0  \n",
       "87569       0.0    0.0      0.0  \n",
       "\n",
       "[87570 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the TRAIN data for approach two and fitting the model\n",
    "\n",
    "model_two_obj = ModelXgBoost(train_array=filtered_df,\n",
    "                             train_target=y_train)\n",
    "model_two_obj.train_model()  # Default h.params (Checkout the code)\n",
    "model_two = model_two_obj.trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"]]\n",
    "x_test = test.drop(columns=[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\", \"SplitPaymentsHistory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For x_test\n",
    "split_payment_history = test[[\"SplitPaymentsHistory\"]]\n",
    "\n",
    "numerical_df_test, encoded_categories_test, encoded_test, encoding_obj_t = encode_and_drop(x_test, \"test\", encoding_obj)\n",
    "filtered_df_test = filter_categorical_features(overall_df=x_test,\n",
    "                                               encoded_frame=encoded_categories_test,\n",
    "                                               categorical_variable=['Occupation', 'Region'])\n",
    "_indexes = filtered_df_test.index\n",
    "\n",
    "# Concatenating with the Numerical frame \n",
    "numerical_frame_test = numerical_df_test[\n",
    "    [\n",
    "#         'Deposit', \n",
    "#         'AccessoryRate', \n",
    "#         'RatePerUnit', \n",
    "#         'DaysOnDeposit', \n",
    "#         'Age',\n",
    "#         'Term', \n",
    "#         'TotalContractValue', \n",
    "        'b1', \n",
    "        'b2', \n",
    "        'b3', \n",
    "        'b4', \n",
    "        'b5'\n",
    "    ]\n",
    "]  # Filtering required variables\n",
    "\n",
    "_index = numerical_frame_test.index\n",
    "filtered_df_test = pd.concat([numerical_frame_test.reset_index(drop=True),\n",
    "                         filtered_df_test.reset_index(drop=True)], axis=1)\n",
    "filtered_df_test.index = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inference on test data\n",
    "predict_dict = dict()\n",
    "for predict_col in y_test.columns:\n",
    "    predict_dict[f\"{predict_col}_pred\"] = model_two.predict(filtered_df_test)\n",
    "    y_pred_df = pd.DataFrame(predict_dict[f\"{predict_col}_pred\"], columns=[f\"{predict_col}_pred\"])\n",
    "    filtered_df_test = pd.concat([filtered_df_test.reset_index(drop=True),\n",
    "                                  y_pred_df.reset_index(drop=True), \n",
    "                                  split_payment_history.reset_index(drop=True)], axis=1)\n",
    "    filtered_df_test.index = _indexes  # Making sure indexes are maintained\n",
    "    filtered_df_test.rename(columns={f\"{predict_col}_pred\": \"new_payment\"}, inplace=True)\n",
    "    filtered_df_test = FeatureEngineering().get_updated_df(base_df=filtered_df_test)\n",
    "    split_payment_history = filtered_df_test[[\"SplitPaymentsHistory\"]]\n",
    "    filtered_df_test.drop(columns=[\"SplitPaymentsHistory\"], inplace=True)\n",
    "\n",
    "del split_payment_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m1_pred': array([1310.7861 ,  702.4433 ,   66.70598, ...,  487.59427, 1531.1561 ,\n",
       "        1318.1704 ], dtype=float32),\n",
       " 'm2_pred': array([1382.9312 ,  781.2366 ,  145.05013, ...,  539.9375 ,  875.3562 ,\n",
       "        1344.1925 ], dtype=float32),\n",
       " 'm3_pred': array([1266.8241 ,  796.75244,  346.39737, ...,  543.747  , 1430.3486 ,\n",
       "        1199.0573 ], dtype=float32),\n",
       " 'm4_pred': array([1029.7507  ,  778.33704 ,    4.754924, ...,  352.84058 ,\n",
       "        1097.7854  , 1513.1829  ], dtype=float32),\n",
       " 'm5_pred': array([3380.2788  , 2559.3103  ,   22.711336, ..., 1729.3048  ,\n",
       "        2379.9187  , 2122.7666  ], dtype=float32),\n",
       " 'm6_pred': array([373.8821   ,  -3.6392024, 373.8821   , ...,  10.214052 ,\n",
       "        373.8821   ,  10.214052 ], dtype=float32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_frame = pd.DataFrame(predict_dict)\n",
    "pred_frame.index = _indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_array = pd.concat([filtered_df_test, y_test, pred_frame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_array = pd.merge(full_test_array, test_id, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file = SubmissionFile(\n",
    "    validation_data=full_test_array,\n",
    "    type_of_data='validation'\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71796, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file['SquaredError'] = np.square(sub_file['Target'] - sub_file['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final RMSE -->  1057.4261713619298\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.sum(sub_file['SquaredError'])/sub_file.shape[0])\n",
    "print('Final RMSE --> ', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aumaron/.local/share/virtualenvs/zindi_payg-FXkRANRI/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion\n",
    "main_train = DataIngestion(mode=\"train\").execute()\n",
    "main_test = DataIngestion(mode=\"test\").execute()\n",
    "\n",
    "main_train.dropna(subset=['Region'], how='all', inplace=True)\n",
    "\n",
    "main_train.drop(columns=['Town'], inplace=True)\n",
    "main_test.drop(columns=['Town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "main_train = FeatureEngineering().execute(main_train)\n",
    "main_test = FeatureEngineering().execute(main_test)\n",
    "main_train.drop(\n",
    "    columns=[\n",
    "        'TransactionDates',\n",
    "        'PaymentsHistory',\n",
    "        'RegistrationDate',\n",
    "        'UpsellDate',\n",
    "        'SupplierName',\n",
    "        'PaymentMethod',\n",
    "        'ExpectedTermDate',\n",
    "        'FirstPaymentDate',\n",
    "        'LastPaymentDate',\n",
    "#         'SplitTransactionDates'\n",
    "    ],\n",
    "    inplace=True\n",
    ")\n",
    "main_test.drop(\n",
    "    columns=[\n",
    "        'TransactionDates',\n",
    "        'PaymentsHistory',\n",
    "        'RegistrationDate',\n",
    "        'UpsellDate',\n",
    "        'SupplierName',\n",
    "        'PaymentMethod',\n",
    "        'ExpectedTermDate',\n",
    "        'FirstPaymentDate',\n",
    "        'LastPaymentDate',\n",
    "#         'SplitTransactionDates'\n",
    "    ],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Train\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "payments_df = main_train[[\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"]]\n",
    "main_y_train = pd.concat([payments_df, payments_df.T.stack().reset_index(name='y')['y']], axis=1)[[\"y\"]]\n",
    "\n",
    "all_x_dfs = {\"df_0\": main_train.drop([\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"], axis=1)}\n",
    "for i in range(1, 6):\n",
    "    temp_df = copy.deepcopy(all_x_dfs[f\"df_{i - 1}\"])\n",
    "    m_df = payments_df[[f\"m{i}\"]]\n",
    "    temp_df = pd.concat([temp_df, m_df], axis=1)\n",
    "    temp_df.rename(columns={f\"m{i}\": \"new_payment\"}, inplace=True)\n",
    "    temp_df = FeatureEngineering().get_updated_df(base_df=temp_df)\n",
    "    all_x_dfs[f\"df_{i}\"] = temp_df\n",
    "\n",
    "x_train_overall = pd.concat([all_x_dfs[f\"df_{i}\"] for i in range(6)], ignore_index=True)\n",
    "x_train_overall.drop(columns=['SplitPaymentsHistory'], inplace=True)\n",
    "del payments_df, temp_df, m_df\n",
    "\n",
    "# ID variable is saved separately\n",
    "x_train_overall.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "main_test_id = main_test[['ID']]\n",
    "main_test.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For x_train_overall\n",
    "overall_numerical_df, overall_encoded_categories, overall_encoded_train, overall_encoding_obj = encode_and_drop(x_train_overall, \"train\", None)\n",
    "\n",
    "overall_filtered_df = filter_categorical_features(overall_df=main_train,\n",
    "                                                  encoded_frame=overall_encoded_categories, \n",
    "                                                  categorical_variable=['Occupation', 'Region'])\n",
    "\n",
    "# Concatenating with the Numerical frame \n",
    "numerical_frame_ov = overall_numerical_df[\n",
    "    [\n",
    "#         'Deposit', \n",
    "#         'AccessoryRate', \n",
    "#         'RatePerUnit', \n",
    "#         'DaysOnDeposit', \n",
    "#         'Age',\n",
    "#         'Term', \n",
    "#         'TotalContractValue', \n",
    "        'b1', \n",
    "        'b2', \n",
    "        'b3', \n",
    "        'b4', \n",
    "        'b5'\n",
    "    ]\n",
    "]  # Filtering required variables\n",
    "\n",
    "_index = numerical_frame_ov.index\n",
    "overall_filtered_df = pd.concat([numerical_frame_ov.reset_index(drop=True),\n",
    "                                 overall_filtered_df.reset_index(drop=True)], axis=1)\n",
    "overall_filtered_df.index = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the TRAIN data for approach two and fitting the model\n",
    "\n",
    "model_two_ov_obj = ModelXgBoost(train_array=overall_filtered_df,\n",
    "                                train_target=main_y_train)\n",
    "model_two_ov_obj.train_model()  # Default h.params (Checkout the code)\n",
    "model_two_ov = model_two_ov_obj.trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For x_test\n",
    "x_test_submission = main_test.drop(columns=[\"SplitPaymentsHistory\"])\n",
    "split_payment_history = main_test[[\"SplitPaymentsHistory\"]]\n",
    "\n",
    "sub_numerical_df_test, sub_encoded_categories_test, sub_encoded_test, sub_encoding_obj_t = encode_and_drop(x_test_submission, \"test\", overall_encoding_obj)\n",
    "sub_filtered_df_test = filter_categorical_features(overall_df=main_test,\n",
    "                                                   encoded_frame=sub_encoded_categories_test, \n",
    "                                                   categorical_variable=['Occupation', 'Region'])\n",
    "_indexes = sub_filtered_df_test.index\n",
    "\n",
    "# Concatenating with the Numerical frame \n",
    "sub_numerical_frame = sub_numerical_df_test[\n",
    "    [\n",
    "#         'Deposit', \n",
    "#         'AccessoryRate', \n",
    "#         'RatePerUnit', \n",
    "#         'DaysOnDeposit', \n",
    "#         'Age',\n",
    "#         'Term', \n",
    "#         'TotalContractValue', \n",
    "        'b1', \n",
    "        'b2', \n",
    "        'b3', \n",
    "        'b4', \n",
    "        'b5'\n",
    "    ]\n",
    "]  # Filtering required variables\n",
    "\n",
    "_index = sub_numerical_frame.index\n",
    "sub_filtered_df_test = pd.concat([sub_numerical_frame.reset_index(drop=True),\n",
    "                                  sub_filtered_df_test.reset_index(drop=True)], axis=1)\n",
    "sub_filtered_df_test.index = _index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on submission data\n",
    "sub_predict_dict = dict()\n",
    "for predict_col in [\"m1\", \"m2\", \"m3\", \"m4\", \"m5\", \"m6\"]:\n",
    "    sub_predict_dict[f\"{predict_col}_pred\"] = model_two_ov.predict(sub_filtered_df_test)\n",
    "    y_pred_df = pd.DataFrame(sub_predict_dict[f\"{predict_col}_pred\"], columns=[f\"{predict_col}_pred\"])\n",
    "    sub_filtered_df_test = pd.concat([sub_filtered_df_test.reset_index(drop=True),\n",
    "                                      y_pred_df.reset_index(drop=True), \n",
    "                                      split_payment_history.reset_index(drop=True)], axis=1)\n",
    "    sub_filtered_df_test.index = _indexes  # Making sure indexes are maintained\n",
    "    sub_filtered_df_test.rename(columns={f\"{predict_col}_pred\": \"new_payment\"}, inplace=True)\n",
    "    sub_filtered_df_test = FeatureEngineering().get_updated_df(base_df=sub_filtered_df_test)\n",
    "    split_payment_history = sub_filtered_df_test[[\"SplitPaymentsHistory\"]]\n",
    "    sub_filtered_df_test.drop(columns=[\"SplitPaymentsHistory\"], inplace=True)\n",
    "\n",
    "del split_payment_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "sub_pred_frame_test = pd.DataFrame(sub_predict_dict)\n",
    "sub_pred_frame_test.index = main_test.index\n",
    "\n",
    "full_test_array_test = pd.concat([main_test, sub_pred_frame_test], axis=1)\n",
    "full_test_array_test = pd.merge(full_test_array_test, main_test_id, how='left', left_index=True, right_index=True)\n",
    "\n",
    "sub_file = SubmissionFile(\n",
    "    validation_data=full_test_array_test,\n",
    "    type_of_data='test'\n",
    ").execute()\n",
    "sub_file.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file.to_csv('../submissions/submission_approach_2_occupation_region_b1_b5_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TASKS\n",
    "# Tasks\n",
    "    - Feature selection  Aum\n",
    "        - Automated selection based on Genie Index\n",
    "\n",
    "    - Pipeline setup  Nikhil\n",
    "        - Pre-process\n",
    "            - ingestion (DONE)\n",
    "            - Features (DONE)\n",
    "            - Encoding (Pending)\n",
    "            - scaling (if applicable)\n",
    "        - Modelling\n",
    "            - Approach2\n",
    "            - Sliding updates for features for Train and test\n",
    "\n",
    "        - validation\n",
    "            - Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Useless Columns\n",
    "def drop_cols(df):\n",
    "    df.drop(\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"UpsellDate\",\n",
    "            \"PaymentMethod\",\n",
    "            \"TransactionDates\",\n",
    "            \"PaymentsHistory\",\n",
    "            \"SupplierName\",\n",
    "            \"Town\",\n",
    "            \"RegistrationDateParsed\",\n",
    "            \"ExpectedTermDateParsed\",\n",
    "            \"FirstPaymentDateParsed\",\n",
    "            \"LastPaymentDateParsed\"\n",
    "        ],\n",
    "        inplace=True,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "drop_cols(train)\n",
    "drop_cols(test)\n",
    "train.head()\n",
    "test.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi_payg",
   "language": "python",
   "name": "zindi_payg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
